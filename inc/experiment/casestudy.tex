\section{Experiments}

In this section, we aim to address the following research question: "How does the state-of-the-art T5-PICARD method perform on the SEOSS Dataset compared to SQLNet and RatSQL, and can general-purpose language models be effectively employed to solve the text-to-SQL problem?" To answer this question, we conduct experiments using the T5-PICARD approach, which has been recently proposed for the SPIDER challenge, and compare its performance to SQLNet and RatSQL, as documented in the SEOSS-Queries research paper\cite{TOMOVA2022108211}. The results of these experiments, presented in the subsequent section, demonstrate the capabilities of the T5-PICARD method in tackling the SPIDER task using the SEOSS Dataset.

Furthermore, considering the recent advancements in large language models and the availability of the ChatGPT APIs, we explore the performance of GPT models on this task. We conduct experiments using the SPIDER and SEOSS datasets and compare the findings to those obtained from earlier experiments with SQLNet and RatSQL. The insights from these experiments, discussed in the following section, shed light on the potential of modern large-scale language models, such as GPT, in addressing the SPIDER task and further contribute to answering our research question. This investigation also helps determine if general-purpose language models can effectively solve the text-to-SQL problem.

\subsection{Limitations}

Our experiment faced several limitations, primarily due to the extensive computational resources required when leveraging the T5 model. For our experiment, we used a single Nvidia RTX 3070 16GB GPU with 20GB Memory, which constrained us to smaller models with tighter restrictions. Despite these limitations, we managed to achieve admirable results. Utilizing a larger T5 model could have led to even higher scores. As a result, investing in a more powerful GPU for our experiment should be considered to capitalize on our model's potential fully.
In addition, during the ChatGPT experiment, cost constraints limited our ability to experiment with GPT-4.0, as its usage cost is approximately 30 times higher than that of GPT-3.5-turbo. We had to experiment with different methods to find the best prompt for ChatGPT to force him to act as a text-to-SQL agent, but this led to wasting money.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|}
        \hline \textbf{Model} & \textbf{Usage}      \\
        \hline GPT-4          & \$0.06 / 1K tokens  \\
        \hline GPT-3.5-turbo  & \$0.002 / 1K tokens \\
        \hline
    \end{tabular}
    \caption{Cost comparison between GPT-4 and GPT-3.5-turbo}
    \label{tab:cost_comparison}
\end{table}

\input{inc/experiment/exp-seoss-t5}
\clearpage
\input{inc/experiment/exp-seoss-gpt}
\input{inc/experiment/exp-spider-gpt}
\clearpage
\input{inc/experiment/exp-ez}